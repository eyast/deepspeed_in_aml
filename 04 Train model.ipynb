{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Walk through training a model on Azure ML using DeepSpeed, registering the resulting model\n",
        "\n",
        "**Goals**: demonstrate how to fine-tune an NLP model on a training cluster with DeepSpeed. \n",
        "\n",
        "This notebook provides a minimal example of configuring and launching a model training run on Azure ML using DeepSpeed as an accelerator for distributed training. We rely on a minimal external training script that is intended to be used as a starting point for adaptation to other workflows: `src/train.py`. Here we'll\n",
        "\n",
        "- Import a configuration file that sets parameters for our training run\n",
        "- Connect to Azure ML and locate the DeepSpeed environment we've built there\n",
        "- Configure a run, using a minimal external training script\n",
        "- Submit our run to a compute cluster\n",
        "- Look at a completed run and the model it registered \n",
        "\n",
        "First we will import the relevant libraries"
      ],
      "metadata": {},
      "id": "eefb569c"
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import azureml.core\n",
        "import transformers"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1701749794064
        }
      },
      "id": "05603b5d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using an external config.yml\n",
        "\n",
        "The `src/config.yml` file contains most of the settings that will need to be customized for a new job type. Reading through it gives a sense of how to configure a run, what sort of information to think about when defining a new experiment. Additionally, by storing values for this notebook and `train.py` in a config file (rather than passing them by argument) we make them far easier to track. Our `train.py` script will ensure that the input config file is copied to the run outputs, preserving it with the run for later reference. \n"
      ],
      "metadata": {},
      "id": "4fc50fbc"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('src/config.yml', 'r') as f:\n",
        "    config = yaml.safe_load(f)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1701749796826
        }
      },
      "id": "f1551894"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the workspace and environment \n",
        "\n",
        "As before, the Azure ML workspace hosts our compute, dataset, future models, and environment. We instantiate a connection to it using a configuration file that is automatically provided on the Azure ML compute instances but which [we must create](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#workspace) if we run this notebook on our own desktop or laptop machine. "
      ],
      "metadata": {},
      "id": "f7a8ce9a"
    },
    {
      "cell_type": "code",
      "source": [
        "workspace = azureml.core.Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1701749800318
        }
      },
      "id": "8779e333-c885-4621-b558-f8b6c2c2912b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The environment we'll connect to is named in the `config.yml` file. It is hosted as a docker image in an AzureContainerRepository and requires no recompilation to start our run, greatly decreasing the time a run takes to begin. We can examine the environment within AzureML studio. "
      ],
      "metadata": {},
      "id": "061e4cbb"
    },
    {
      "cell_type": "code",
      "source": [
        "azureml.core.Environment.list(workspace).keys()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "dict_keys(['aml-scikit-learn', 'ray-on-aml-3734189943', 'ray-on-aml-2220177819', 'deepspeed-transformers', 'deepspeed-transformers-datasets', 'AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu'])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1701749812442
        }
      },
      "id": "c97d7a31-3860-409d-a12a-3a7192111bd2"
    },
    {
      "cell_type": "code",
      "source": [
        "# environment = azureml.core.Environment.get(workspace, config['environment'])\n",
        "env_name = \"deepspeed-transformers-datasets\"\n",
        "environment = azureml.core.Environment.get(workspace, name=env_name)\n",
        "print(environment)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment(Name: deepspeed-transformers-datasets,\nVersion: 4)\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1701749813611
        }
      },
      "id": "6a34ff48"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment\n",
        "\n",
        "Connect to (or create) the experiment that will host the training run we'll launch. A single experiment can host many runs, each exploring a different set of parameters, architecture, or other approach to a the same problem. Metrics from multiple runs within a single experiment can be plotted against each other in AzureML studio. "
      ],
      "metadata": {},
      "id": "6a5f2b57"
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = azureml.core.Experiment(workspace, config['experiment'])"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1701749815837
        }
      },
      "id": "f6800e86"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure and submit the run\n",
        "\n",
        "Our run requires several configuration components. It is worth examining the relevant entries in the `sec/config.yml` to see what we are passing and the structure of `src/train.py` to see what the training script does on each node. A summary:\n",
        "\n",
        "- a distributed job config controls the underlying PyTorch parallelization process, here this means the machine and GPUs/machine counts\n",
        "- a [ScriptRunConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py) that describes the run to the AzureML run controller, where we glue together the compute target, the environment, and the training command\n",
        "- a command run by the ScriptRunConfig, here a simple call out to `src/train.py`\n",
        "- an implicit Deepspeed configuration, referenced within the `src/train.py`"
      ],
      "metadata": {},
      "id": "e7b62de3-53c5-43fa-8ab5-0b7a4f8f1fc3"
    },
    {
      "cell_type": "code",
      "source": [
        "distributed_job_config = azureml.core.runconfig.PyTorchConfiguration(**config['pytorch_configuration'])\n",
        "aml_config = azureml.core.ScriptRunConfig(\n",
        "             source_directory=config['source_directory'],\n",
        "             command=config['training_command'],\n",
        "             environment=environment,\n",
        "             compute_target=config['compute_target'],\n",
        "             distributed_job_config=distributed_job_config,\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1701749845994
        }
      },
      "id": "fcb9a50f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the run configured we submit it and tag it with metadata tags that will be helpful in understanding it later. Each of these tags is discoverable within the `src/config.yml` which will be included with the run's output, but by writing them here as well they become visible within the AzureML studio interface. We link to the AzureML studio entry for this run in the url below."
      ],
      "metadata": {},
      "id": "c5479712"
    },
    {
      "cell_type": "code",
      "source": [
        "run = experiment.submit(aml_config)\n",
        "run.set_tags({\n",
        "    \"model\":config['model'], \n",
        "    \"task\":config['task'],\n",
        "    \"metric\":config['metric'],\n",
        "    \"environment\":config['environment'],\n",
        "    \"num_train_epochs\":str(config['training_args']['num_train_epochs']),\n",
        "    \"batch_size\":str(config['training_args']['per_device_train_batch_size'])\n",
        "})\n",
        "\n",
        "print(f\"View run details:\\n{run.get_portal_url()}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "View run details:\nhttps://ml.azure.com/runs/training-quickstart_1701749848_41715b81?wsid=/subscriptions/f3692ca7-e0d1-4bd3-92f8-49832ab6be7d/resourcegroups/eyast-rg/workspaces/xcs224&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1701749851127
        }
      },
      "id": "668a717a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with the run output\n",
        "\n",
        "Now we wait for that run to complete, checking AzureML studio or calling  `run.get_status()` to verify that it is done."
      ],
      "metadata": {},
      "id": "52ed5813"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Run status: {run.get_status()}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "9e96dd01-e445-45e8-85ce-50f33c92c392"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ending {config['metric']}: {run.get_metrics()['eval_'+config['metric']][-1]:.2f}\")\n",
        "print(f\"View run details:\\n{run.get_portal_url()}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "4930a3eb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can download the model that was registered. The model name and version, uniquely identifying it, are metadata tags associated with the run."
      ],
      "metadata": {},
      "id": "d2df54a3"
    },
    {
      "cell_type": "code",
      "source": [
        "aml_model = azureml.core.Model(workspace,\n",
        "                               name=run.tags['registered_model_name'],\n",
        "                               version=run.tags['registered_model_version']\n",
        "                                    )\n",
        "aml_model.download(exist_ok=True);"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "a1455551"
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the model copied to our local drive, we can convert it to ONNX format, push it to the Triton model serving container, ready it for compression, or perform some testing inference with it as we do now. We load the model and the associated tokenizer using the transformers library that wrote them out in `src/train.py` and chain them into a classification pipeline.\n"
      ],
      "metadata": {},
      "id": "e5528055"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"model\")\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"model\", id2label=['negative', 'positive'])\n",
        "pipeline = transformers.TextClassificationPipeline(model=model, tokenizer=tokenizer)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "1cbf30c4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The task this model was trained on, [CoLA](https://nyu-mll.github.io/CoLA/), attempts to classify sentences as grammatical or ungrammatical. We'll feed it some examples."
      ],
      "metadata": {},
      "id": "ea35075f-6299-4207-a2bc-586ad2ea8956"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = (\"i like pie\", \"books sent other the students\")\n",
        "for sentence in sentences:\n",
        "    print(f\"Is '{sentence}' grammatical?: {pipeline(sentence)[0]['label']}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "2f80bd5b-353d-4d28-ab23-71d196132e1d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we've:\n",
        "\n",
        "- connected to an AzureML workspace\n",
        "- started a training run using a specified training script and environment\n",
        "- retrieved results from that run\n",
        "- used those results to perform some inferential steps"
      ],
      "metadata": {},
      "id": "bee0e5a7-a334-45af-a9a6-a8735acd5cf3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}